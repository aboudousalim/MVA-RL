{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DL_TP1_DeepRL_MVA (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl-FFUwOvqEN",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGtjYXlvqEQ",
        "colab_type": "code",
        "outputId": "7381b31d-76fe-4fec-ee50-d4fd45ca85b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install scikit-video\n",
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "from numpy import random\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd, adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, Reshape, BatchNormalization, Flatten, Dropout\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRqSWi06vqEc",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojzYb58dvqEe",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flpctupLvqEg",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGeht01jvqEi",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buULq14-vqEk",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hqoytk-vqEm",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wejYY9QdvqEo",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnrh1RbAvqEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J3r8b8kvqE1",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5k5l91NvqE4",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-XwJNsovqFD",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTcZq8xovqFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1I52rhHvqFR",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad7F1HsWvqFV",
        "colab_type": "text"
      },
      "source": [
        "The function act returns what action the agent will choose based on the current state. \n",
        "\n",
        "The epsilon parameter allows to control the exploration, this what we call the $\\epsilon$-greedy strategy. The epsilon parameter is essential because if epsilon = 0 we will follow the action based on what we have learned only ie the strategy with the best reward till now. \n",
        "\n",
        "With the function act, the actor chooses a random action with probability $\\epsilon$ and act via its policy with a probability $1-\\epsilon$. \n",
        "\n",
        "It's a pramater of a trade-off exploration-exploitation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvgPv-oJvqFW",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHlXdlnjvqFY",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbft5aMivqFZ",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6z4XboQvqFb",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaQYT_CUvqFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLqXxqUsvqFl",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kt9tkwsvqFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=20 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaje-m7NvqFz",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY2NHPnwvqF1",
        "colab_type": "text"
      },
      "source": [
        "* The array ``board`` defines the distribution of the rewards over the $N\\times N$ grid. It stores the reward of being in each cell that we can access through the coordinates x and y of the agent. \n",
        "\n",
        "* The array ``position`` defines the borders of the grid, the allowed states and the position of the agent. At each step, a value of -1 is assigned for the cells representing the borders (ie the states that can't be visited), a value of 0 is assigned for all the other cells that can be visited, and a value of 1 is assigned for the current cell occupied by the agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HTsb1EVvqF4",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LJXOgkhvqF5",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWNSNlSfvqF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(0, self.n_action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmcLGstvqG1",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJK8HsvvqG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        \n",
        "        state = env.reset()\n",
        "        game_over = False # We know that the games will end in infinity\n",
        "\n",
        "        win, lose = 0, 0\n",
        "        \n",
        "        while not game_over:\n",
        "            \n",
        "            action = agent.learned_act(state)\n",
        "            state,reward,game_over = env.act(action)\n",
        "\n",
        "            if reward > 0:\n",
        "                win += reward \n",
        "            if reward < 0:\n",
        "                lose -= reward\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc9fUnvWvqHA",
        "colab_type": "code",
        "outputId": "df744911-053c-4452-c1cf-368368781028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.0/17.0. Average score (-7.0)\n",
            "Win/lose count 9.5/15.0. Average score (-6.25)\n",
            "Win/lose count 7.0/16.0. Average score (-7.166666666666667)\n",
            "Win/lose count 8.5/12.0. Average score (-6.25)\n",
            "Win/lose count 8.5/12.0. Average score (-5.7)\n",
            "Win/lose count 13.5/24.0. Average score (-6.5)\n",
            "Win/lose count 12.5/16.0. Average score (-6.071428571428571)\n",
            "Win/lose count 9.0/7.0. Average score (-5.0625)\n",
            "Win/lose count 10.5/21.0. Average score (-5.666666666666667)\n",
            "Win/lose count 9.5/9.0. Average score (-5.05)\n",
            "Final score: -5.05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mQQTLm6vqHM",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y1actVIvqHN",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGDEEEauvqHO",
        "colab_type": "text"
      },
      "source": [
        "1 - We have:$$\n",
        "\\begin{align*} \n",
        "Q^\\pi(s,a)&=E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=E_{p^{\\pi}}[r(s_0,a_0) + \\gamma\\sum_{t=1}^{\\infty}\\gamma^{t-1}r(s_{t},a_{t})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a]\\\\\n",
        "          &=r(s,a) + E_{(s',a')\\sim p(.|s,a)}\\left(\\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']\\right)\\\\\n",
        "          &=E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma E_{p^{\\pi}}[\\sum_{t=0}^{\\infty}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']\\right)\\\\\n",
        "          &=E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma Q^{\\pi}(s',a') \\right)\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "2 - We have $\\pi^*(s') = arg\\max_{a'} Q^{*}(s',a')$, which is deterministic, so:$$\n",
        "\\begin{align*}\n",
        "Q^*(s,a)&= E_{(s',a')\\sim p(.|s,a)}\\left(r(s,a) + \\gamma Q^{*}(s',a') \\right)\\\\\n",
        "        &= E_{s'\\sim p(.|s,a)\\,and\\,a'\\sim \\pi^*(.|s')}\\left(r(s,a) + \\gamma Q^{*}(s',a') \\right)\\\\\n",
        "        &= E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q^{*}(s',a') \\right)\\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "3 - We know that $$Q^*(s,a)=E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q^{*}(s',a') \\right)$$\n",
        "\n",
        "Therefore, $Q^*$ is the solution of the equation $F(Q) = 0$ with:\n",
        "$$F(Q) = E_{s' \\sim \\pi^*(.|s,a)}\\left(r(s,a) + \\gamma \\max_{a'}Q(s',a') - Q(s,a)\\right)$$\n",
        "\n",
        "So minimizing $\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}$ will lead us to find $Q^*$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfBxBwVivqHP",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu9P-KmUvqHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) <= self.max_memory:\n",
        "            self.memory.append(m)\n",
        "        else:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(len(self.memory))]        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_nbQs4avqHV",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHk4kHjzvqHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z634jkgFvqHc",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RfDCMZzvqHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # Number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape([1, s.shape[0], s.shape[1], s.shape[2]]))[0, :])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        on_batch = min(self.batch_size, len(self.memory.memory))\n",
        "        input_states = np.zeros((on_batch, 5, 5, self.n_state))  \n",
        "        target_q = np.zeros((on_batch, self.n_action))           \n",
        "        \n",
        "        for i in range(on_batch):\n",
        "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access() \n",
        "            target_q[i] = self.model.predict(s_.reshape(1, 5, 5, self.n_state))\n",
        "            input_states[i] = s_\n",
        "            \n",
        "            if game_over_:\n",
        "                target_q[i, a_] = r_          \n",
        "            else:\n",
        "                target_q[i, a_] = r_ + self.discount*self.model.predict(n_s_.reshape(1, 5, 5, self.n_state)).max()\n",
        "                \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5,5,self.n_state,)))\n",
        "        model.add(Dense(30,activation ='relu'))\n",
        "        model.add(Dense(4, activation = None))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmo2I5s-vqHk",
        "colab_type": "code",
        "outputId": "510753c6-8b37-4e2a-cd0b-3ff679861e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "epochs_train = 40\n",
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=1e-1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/040 | Loss 0.0117 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 001/040 | Loss 0.0074 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 002/040 | Loss 0.0071 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 003/040 | Loss 0.0079 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 004/040 | Loss 0.0060 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 005/040 | Loss 0.0038 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 006/040 | Loss 0.0134 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 007/040 | Loss 0.0098 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 008/040 | Loss 0.0056 | Win/lose count 6.5/6.0 (0.5)\n",
            "Epoch 009/040 | Loss 0.0055 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 010/040 | Loss 0.0045 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 011/040 | Loss 0.0085 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 012/040 | Loss 0.0090 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 013/040 | Loss 0.0104 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 014/040 | Loss 0.0051 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 015/040 | Loss 0.0697 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 016/040 | Loss 0.0033 | Win/lose count 8.5/4.0 (4.5)\n",
            "Epoch 017/040 | Loss 0.0029 | Win/lose count 9.5/3.0 (6.5)\n",
            "Epoch 018/040 | Loss 0.0578 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 019/040 | Loss 0.0041 | Win/lose count 6.0/0 (6.0)\n",
            "Epoch 020/040 | Loss 0.0037 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 021/040 | Loss 0.0070 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 022/040 | Loss 0.0035 | Win/lose count 8.0/2.0 (6.0)\n",
            "Epoch 023/040 | Loss 0.0032 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 024/040 | Loss 0.0025 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 025/040 | Loss 0.0057 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 026/040 | Loss 0.0042 | Win/lose count 7.5/4.0 (3.5)\n",
            "Epoch 027/040 | Loss 0.0514 | Win/lose count 9.5/1.0 (8.5)\n",
            "Epoch 028/040 | Loss 0.0028 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 029/040 | Loss 0.0034 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 030/040 | Loss 0.0581 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 031/040 | Loss 0.0637 | Win/lose count 8.5/3.0 (5.5)\n",
            "Epoch 032/040 | Loss 0.0028 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 033/040 | Loss 0.0018 | Win/lose count 0.5/2.0 (-1.5)\n",
            "Epoch 034/040 | Loss 0.0041 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 035/040 | Loss 0.0552 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 036/040 | Loss 0.0017 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 037/040 | Loss 0.0017 | Win/lose count 9.0/5.0 (4.0)\n",
            "Epoch 038/040 | Loss 0.0026 | Win/lose count 17.5/5.0 (12.5)\n",
            "Epoch 039/040 | Loss 0.0019 | Win/lose count 5.5/7.0 (-1.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD4WlIkMvqHo",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HIgXldxvqHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers as reg\n",
        "\n",
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        # First model\n",
        "        # model = Sequential()\n",
        "        # model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "        # model.add(Conv2D(16, (2, 2), activation='relu'))\n",
        "        # model.add(Flatten())\n",
        "        # model.add(Dense(4, activation='linear'))\n",
        "\n",
        "        # Final model\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(50, (2,2), input_shape=(5, 5, self.n_state,), activation='relu'))\n",
        "        model.add(Conv2D(30, (2,2), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4))\n",
        "\n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPOiH5WTvqHv",
        "colab_type": "code",
        "outputId": "bcc16058-b2d3-4fda-c106-bf6e893028d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/040 | Loss 0.0052 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 001/040 | Loss 0.0062 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 002/040 | Loss 0.0030 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 003/040 | Loss 0.0059 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 004/040 | Loss 0.0014 | Win/lose count 4.0/4.0 (0.0)\n",
            "Epoch 005/040 | Loss 0.0054 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 006/040 | Loss 0.0039 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 007/040 | Loss 0.0540 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 008/040 | Loss 0.0043 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 009/040 | Loss 0.0040 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 010/040 | Loss 0.0016 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 011/040 | Loss 0.0045 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 012/040 | Loss 0.1061 | Win/lose count 10.0/3.0 (7.0)\n",
            "Epoch 013/040 | Loss 0.0005 | Win/lose count 11.5/2.0 (9.5)\n",
            "Epoch 014/040 | Loss 0.0596 | Win/lose count 10.5/2.0 (8.5)\n",
            "Epoch 015/040 | Loss 0.0012 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 016/040 | Loss 0.0011 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 017/040 | Loss 0.0525 | Win/lose count 12.0/4.0 (8.0)\n",
            "Epoch 018/040 | Loss 0.0007 | Win/lose count 2.5/0 (2.5)\n",
            "Epoch 019/040 | Loss 0.0547 | Win/lose count 18.5/2.0 (16.5)\n",
            "Epoch 020/040 | Loss 0.0020 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 021/040 | Loss 0.0520 | Win/lose count 11.0/3.0 (8.0)\n",
            "Epoch 022/040 | Loss 0.0013 | Win/lose count 13.0/2.0 (11.0)\n",
            "Epoch 023/040 | Loss 0.0484 | Win/lose count 8.5/2.0 (6.5)\n",
            "Epoch 024/040 | Loss 0.0019 | Win/lose count 8.5/1.0 (7.5)\n",
            "Epoch 025/040 | Loss 0.0032 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 026/040 | Loss 0.0528 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 027/040 | Loss 0.0038 | Win/lose count 12.0/2.0 (10.0)\n",
            "Epoch 028/040 | Loss 0.0021 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 029/040 | Loss 0.0024 | Win/lose count 10.0/5.0 (5.0)\n",
            "Epoch 030/040 | Loss 0.0012 | Win/lose count 9.0/2.0 (7.0)\n",
            "Epoch 031/040 | Loss 0.0503 | Win/lose count 9.0/0 (9.0)\n",
            "Epoch 032/040 | Loss 0.0012 | Win/lose count 25.5/1.0 (24.5)\n",
            "Epoch 033/040 | Loss 0.0487 | Win/lose count 10.5/4.0 (6.5)\n",
            "Epoch 034/040 | Loss 0.0014 | Win/lose count 12.0/2.0 (10.0)\n",
            "Epoch 035/040 | Loss 0.0097 | Win/lose count 10.0/1.0 (9.0)\n",
            "Epoch 036/040 | Loss 0.0529 | Win/lose count 14.0/1.0 (13.0)\n",
            "Epoch 037/040 | Loss 0.0064 | Win/lose count 6.0/1.0 (5.0)\n",
            "Epoch 038/040 | Loss 0.0022 | Win/lose count 4.5/2.0 (2.5)\n",
            "Epoch 039/040 | Loss 0.0022 | Win/lose count 6.0/2.0 (4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEwWpy5cvqH0",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSKL0ga6vqH1",
        "colab_type": "code",
        "outputId": "44d8a021-b697-4c7b-a058-45d8baa14c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 8.0/0. Average score (8.0)\n",
            "Win/lose count 1.0/0. Average score (4.5)\n",
            "Win/lose count 4.0/0. Average score (4.333333333333333)\n",
            "Win/lose count 8.0/0. Average score (5.25)\n",
            "Win/lose count 4.0/0. Average score (5.0)\n",
            "Win/lose count 1.0/0. Average score (4.333333333333333)\n",
            "Win/lose count 9.5/0. Average score (5.071428571428571)\n",
            "Win/lose count 5.0/0. Average score (5.0625)\n",
            "Win/lose count 11.5/0. Average score (5.777777777777778)\n",
            "Win/lose count 4.0/0. Average score (5.6)\n",
            "Final score: 5.6\n",
            "Test of the FC\n",
            "Win/lose count 1.0/0. Average score (1.0)\n",
            "Win/lose count 4.5/1.0. Average score (2.25)\n",
            "Win/lose count 2.0/0. Average score (2.1666666666666665)\n",
            "Win/lose count 4.0/0. Average score (2.625)\n",
            "Win/lose count 2.5/0. Average score (2.6)\n",
            "Win/lose count 2.5/0. Average score (2.5833333333333335)\n",
            "Win/lose count 3.5/1.0. Average score (2.5714285714285716)\n",
            "Win/lose count 1.5/0. Average score (2.4375)\n",
            "Win/lose count 0.5/0. Average score (2.2222222222222223)\n",
            "Win/lose count 1.0/0. Average score (2.1)\n",
            "Final score: 2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHJzusw7vqH6",
        "colab_type": "code",
        "outputId": "6b1e27d7-0ae9-4b2d-ef63-bc98cb760bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJrpI6XAvqH9",
        "colab_type": "code",
        "outputId": "36f849d2-9286-44aa-e00c-43f322b39389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqiy942mvqIA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* We notice that the agent doesn't explore the map well and sometimes get stuck in a position, when there is no positive reward within his visibility, especially for the agent with the fully connected network.\n",
        "\n",
        "* When we increase the temperature, positive rewards cells get numerous, which helps the agent explore the map since more positive cells gets in his visibility, and therefore the final average score gets higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vujkg1uWvqIB",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMqQtUYfvqIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent, env, epoch, prefix=''):\n",
        "    score, loss, step = 0, 0, 0\n",
        "    eps_start = agent.epsilon\n",
        "    eps_final, decay_rate = 0.1, 0.0005\n",
        "\n",
        "    for e in range(epoch):\n",
        "        state = env.reset() # We refresh the game at each begin of an epoch\n",
        "        game_over = False # We assume that the game will finish\n",
        "\n",
        "        win, lose = 0, 0\n",
        "        \n",
        "        while not game_over:\n",
        "            action = agent.act(state)\n",
        "            eps = eps_final + (eps_start - eps_final) * np.exp(-step * decay_rate)\n",
        "            step += 1\n",
        "            agent.set_epsilon(eps)\n",
        "            \n",
        "            # Act action and get reward and new state\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "            reward -= env.malus_position[env.x, env.y]\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win += reward\n",
        "            elif reward < 0:\n",
        "                lose -= reward\n",
        "\n",
        "            # Apply reinforcement function\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if (e + 1) % 10 == 0:\n",
        "            env.draw(prefix+str(e + 1))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {:.1f}/{:.1f} ({}) | explore_proba {:.2f}\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose, eps))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "\n",
        "class EnvironmentExploring(object):\n",
        "    \n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "        # Board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size)) \n",
        "        # Coordinate\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "        # Time\n",
        "        self.t = 0\n",
        "        self.scale=16\n",
        "        # To draw\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "    \n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "        \n",
        "    def reset(self):\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        # Bonus\n",
        "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size ** 2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "        # Malus\n",
        "        malus = -1.0 * np.random.binomial(1, self.temperature, size=self.grid_size ** 2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "        malus[bonus > 0]=0\n",
        "        # Draw\n",
        "        self.to_draw = np.zeros((self.max_time + 2, self.grid_size * self.scale, self.grid_size * self.scale, 3))\n",
        "        # Board\n",
        "        self.board = bonus + malus\n",
        "        self.malus_position = 0 * self.board\n",
        "        # Position\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "       \n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state      \n",
        "     \n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size, self.grid_size, 3)) + 128\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[self.board > 0, 0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "        self.to_draw[t,:,:,:] = b\n",
        "\n",
        "    def act(self, action,train = False):\n",
        "        # Get frame\n",
        "        self.get_frame(int(self.t))\n",
        "        # Position\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.position[self.x, self.y] = 1\n",
        "        # Analyze on the action type\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "        # Time step\n",
        "        self.t = self.t + 1\n",
        "        # Reward\n",
        "        reward = 0\n",
        "        if train:\n",
        "          reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        # State\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "        return state, reward, game_over"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBHjaPHZLuhZ",
        "colab_type": "code",
        "outputId": "47272db9-02bf-4ad2-c9c0-d89447ff3e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=150\n",
        "epochs_test=20\n",
        "\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=1e-3, epsilon = 0.9, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent_cnn, env, 150, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore90.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/150 | Loss 0.0174 | Win/lose count 6.4/39.5 (-33.10000000000013) | explore_proba 0.82\n",
            "Epoch 001/150 | Loss 0.0128 | Win/lose count 8.0/38.1 (-30.10000000000015) | explore_proba 0.75\n",
            "Epoch 002/150 | Loss 0.0101 | Win/lose count 6.0/31.6 (-25.60000000000013) | explore_proba 0.69\n",
            "Epoch 003/150 | Loss 0.0080 | Win/lose count 15.2/29.3 (-14.100000000000088) | explore_proba 0.64\n",
            "Epoch 004/150 | Loss 0.0069 | Win/lose count 3.6/28.2 (-24.600000000000087) | explore_proba 0.58\n",
            "Epoch 005/150 | Loss 0.0067 | Win/lose count 6.0/25.6 (-19.60000000000011) | explore_proba 0.54\n",
            "Epoch 006/150 | Loss 0.0043 | Win/lose count 14.0/26.6 (-12.600000000000108) | explore_proba 0.50\n",
            "Epoch 007/150 | Loss 0.0753 | Win/lose count 12.4/26.0 (-13.600000000000055) | explore_proba 0.46\n",
            "Epoch 008/150 | Loss 0.0059 | Win/lose count 10.0/26.6 (-16.60000000000009) | explore_proba 0.42\n",
            "Epoch 009/150 | Loss 0.0048 | Win/lose count 16.0/26.1 (-10.100000000000051) | explore_proba 0.39\n",
            "Epoch 010/150 | Loss 0.0080 | Win/lose count 11.2/28.3 (-17.100000000000094) | explore_proba 0.36\n",
            "Epoch 011/150 | Loss 0.0065 | Win/lose count 10.4/26.5 (-16.100000000000094) | explore_proba 0.34\n",
            "Epoch 012/150 | Loss 0.0075 | Win/lose count 12.0/23.1 (-11.10000000000005) | explore_proba 0.32\n",
            "Epoch 013/150 | Loss 0.0067 | Win/lose count 14.0/24.6 (-10.600000000000058) | explore_proba 0.30\n",
            "Epoch 014/150 | Loss 0.0068 | Win/lose count 14.4/21.5 (-7.100000000000042) | explore_proba 0.28\n",
            "Epoch 015/150 | Loss 0.0077 | Win/lose count 13.2/26.8 (-13.600000000000087) | explore_proba 0.26\n",
            "Epoch 016/150 | Loss 0.0367 | Win/lose count 14.4/24.5 (-10.100000000000078) | explore_proba 0.24\n",
            "Epoch 017/150 | Loss 0.0048 | Win/lose count 15.6/22.2 (-6.600000000000055) | explore_proba 0.23\n",
            "Epoch 018/150 | Loss 0.0089 | Win/lose count 16.8/21.9 (-5.100000000000033) | explore_proba 0.22\n",
            "Epoch 019/150 | Loss 0.0041 | Win/lose count 15.2/23.3 (-8.100000000000017) | explore_proba 0.21\n",
            "Epoch 020/150 | Loss 0.0088 | Win/lose count 18.4/19.5 (-1.1000000000000156) | explore_proba 0.20\n",
            "Epoch 021/150 | Loss 0.0089 | Win/lose count 12.0/25.1 (-13.100000000000032) | explore_proba 0.19\n",
            "Epoch 022/150 | Loss 0.0205 | Win/lose count 17.2/23.8 (-6.600000000000019) | explore_proba 0.18\n",
            "Epoch 023/150 | Loss 0.0240 | Win/lose count 17.6/24.7 (-7.100000000000037) | explore_proba 0.17\n",
            "Epoch 024/150 | Loss 0.0076 | Win/lose count 20.4/20.0 (0.39999999999996305) | explore_proba 0.16\n",
            "Epoch 025/150 | Loss 0.0061 | Win/lose count 17.6/20.7 (-3.100000000000037) | explore_proba 0.16\n",
            "Epoch 026/150 | Loss 0.0321 | Win/lose count 17.2/18.8 (-1.5999999999999979) | explore_proba 0.15\n",
            "Epoch 027/150 | Loss 0.0067 | Win/lose count 7.6/23.2 (-15.600000000000062) | explore_proba 0.15\n",
            "Epoch 028/150 | Loss 0.0049 | Win/lose count 17.2/18.8 (-1.6000000000000014) | explore_proba 0.14\n",
            "Epoch 029/150 | Loss 0.0064 | Win/lose count 15.2/22.3 (-7.100000000000042) | explore_proba 0.14\n",
            "Epoch 030/150 | Loss 0.0060 | Win/lose count 16.4/20.0 (-3.6000000000000156) | explore_proba 0.14\n",
            "Epoch 031/150 | Loss 0.0050 | Win/lose count 22.0/19.6 (2.3999999999999737) | explore_proba 0.13\n",
            "Epoch 032/150 | Loss 0.0084 | Win/lose count 15.6/20.2 (-4.600000000000019) | explore_proba 0.13\n",
            "Epoch 033/150 | Loss 0.0060 | Win/lose count 18.0/20.6 (-2.60000000000003) | explore_proba 0.13\n",
            "Epoch 034/150 | Loss 0.0052 | Win/lose count 16.0/21.1 (-5.100000000000019) | explore_proba 0.12\n",
            "Epoch 035/150 | Loss 0.0056 | Win/lose count 16.4/21.0 (-4.600000000000001) | explore_proba 0.12\n",
            "Epoch 036/150 | Loss 0.0076 | Win/lose count 20.0/22.1 (-2.1000000000000547) | explore_proba 0.12\n",
            "Epoch 037/150 | Loss 0.0061 | Win/lose count 18.8/22.4 (-3.600000000000037) | explore_proba 0.12\n",
            "Epoch 038/150 | Loss 0.0382 | Win/lose count 16.8/17.9 (-1.0999999999999872) | explore_proba 0.12\n",
            "Epoch 039/150 | Loss 0.0080 | Win/lose count 13.2/19.8 (-6.599999999999998) | explore_proba 0.11\n",
            "Epoch 040/150 | Loss 0.0100 | Win/lose count 13.6/18.7 (-5.099999999999978) | explore_proba 0.11\n",
            "Epoch 041/150 | Loss 0.0104 | Win/lose count 17.2/18.8 (-1.6000000000000014) | explore_proba 0.11\n",
            "Epoch 042/150 | Loss 0.0080 | Win/lose count 12.8/18.9 (-6.099999999999996) | explore_proba 0.11\n",
            "Epoch 043/150 | Loss 0.0060 | Win/lose count 12.8/23.9 (-11.10000000000005) | explore_proba 0.11\n",
            "Epoch 044/150 | Loss 0.0289 | Win/lose count 13.2/22.8 (-9.600000000000026) | explore_proba 0.11\n",
            "Epoch 045/150 | Loss 0.0102 | Win/lose count 16.8/18.9 (-2.1000000000000014) | explore_proba 0.11\n",
            "Epoch 046/150 | Loss 0.0077 | Win/lose count 16.8/19.9 (-3.1000000000000014) | explore_proba 0.11\n",
            "Epoch 047/150 | Loss 0.0053 | Win/lose count 14.8/18.4 (-3.5999999999999908) | explore_proba 0.11\n",
            "Epoch 048/150 | Loss 0.0064 | Win/lose count 17.6/21.7 (-4.100000000000019) | explore_proba 0.11\n",
            "Epoch 049/150 | Loss 0.0041 | Win/lose count 12.8/20.9 (-8.100000000000032) | explore_proba 0.11\n",
            "Epoch 050/150 | Loss 0.0053 | Win/lose count 19.2/20.3 (-1.1000000000000192) | explore_proba 0.10\n",
            "Epoch 051/150 | Loss 0.0089 | Win/lose count 16.8/19.9 (-3.1000000000000156) | explore_proba 0.10\n",
            "Epoch 052/150 | Loss 0.0086 | Win/lose count 15.6/20.2 (-4.600000000000019) | explore_proba 0.10\n",
            "Epoch 053/150 | Loss 0.0078 | Win/lose count 19.6/21.2 (-1.6000000000000547) | explore_proba 0.10\n",
            "Epoch 054/150 | Loss 0.0357 | Win/lose count 14.0/20.6 (-6.6000000000000085) | explore_proba 0.10\n",
            "Epoch 055/150 | Loss 0.0252 | Win/lose count 14.4/19.5 (-5.099999999999982) | explore_proba 0.10\n",
            "Epoch 056/150 | Loss 0.0082 | Win/lose count 14.0/19.6 (-5.6000000000000085) | explore_proba 0.10\n",
            "Epoch 057/150 | Loss 0.0070 | Win/lose count 17.2/20.8 (-3.6000000000000156) | explore_proba 0.10\n",
            "Epoch 058/150 | Loss 0.0064 | Win/lose count 17.2/19.8 (-2.6000000000000156) | explore_proba 0.10\n",
            "Epoch 059/150 | Loss 0.0069 | Win/lose count 14.4/17.5 (-3.0999999999999748) | explore_proba 0.10\n",
            "Epoch 060/150 | Loss 0.0078 | Win/lose count 13.6/22.7 (-9.10000000000001) | explore_proba 0.10\n",
            "Epoch 061/150 | Loss 0.0165 | Win/lose count 14.0/17.6 (-3.5999999999999766) | explore_proba 0.10\n",
            "Epoch 062/150 | Loss 0.0131 | Win/lose count 14.8/22.4 (-7.600000000000023) | explore_proba 0.10\n",
            "Epoch 063/150 | Loss 0.0247 | Win/lose count 13.6/19.7 (-6.10000000000001) | explore_proba 0.10\n",
            "Epoch 064/150 | Loss 0.0042 | Win/lose count 13.6/20.7 (-7.10000000000001) | explore_proba 0.10\n",
            "Epoch 065/150 | Loss 0.0043 | Win/lose count 10.4/20.5 (-10.100000000000007) | explore_proba 0.10\n",
            "Epoch 066/150 | Loss 0.0051 | Win/lose count 13.6/19.7 (-6.10000000000001) | explore_proba 0.10\n",
            "Epoch 067/150 | Loss 0.0101 | Win/lose count 13.2/22.8 (-9.600000000000026) | explore_proba 0.10\n",
            "Epoch 068/150 | Loss 0.0097 | Win/lose count 13.6/19.7 (-6.099999999999996) | explore_proba 0.10\n",
            "Epoch 069/150 | Loss 0.0079 | Win/lose count 14.8/18.4 (-3.5999999999999908) | explore_proba 0.10\n",
            "Epoch 070/150 | Loss 0.0103 | Win/lose count 13.2/19.8 (-6.600000000000012) | explore_proba 0.10\n",
            "Epoch 071/150 | Loss 0.0106 | Win/lose count 16.8/19.9 (-3.100000000000019) | explore_proba 0.10\n",
            "Epoch 072/150 | Loss 0.0126 | Win/lose count 12.0/24.1 (-12.10000000000007) | explore_proba 0.10\n",
            "Epoch 073/150 | Loss 0.0059 | Win/lose count 12.8/19.9 (-7.1) | explore_proba 0.10\n",
            "Epoch 074/150 | Loss 0.0112 | Win/lose count 12.4/22.0 (-9.600000000000044) | explore_proba 0.10\n",
            "Epoch 075/150 | Loss 0.0086 | Win/lose count 11.2/21.3 (-10.100000000000042) | explore_proba 0.10\n",
            "Epoch 076/150 | Loss 0.0065 | Win/lose count 12.8/20.9 (-8.100000000000032) | explore_proba 0.10\n",
            "Epoch 077/150 | Loss 0.0064 | Win/lose count 18.0/17.6 (0.4000000000000128) | explore_proba 0.10\n",
            "Epoch 078/150 | Loss 0.0111 | Win/lose count 13.2/21.8 (-8.600000000000044) | explore_proba 0.10\n",
            "Epoch 079/150 | Loss 0.0075 | Win/lose count 15.2/22.3 (-7.1000000000000245) | explore_proba 0.10\n",
            "Epoch 080/150 | Loss 0.0087 | Win/lose count 12.4/20.0 (-7.600000000000019) | explore_proba 0.10\n",
            "Epoch 081/150 | Loss 0.0108 | Win/lose count 18.8/18.4 (0.3999999999999986) | explore_proba 0.10\n",
            "Epoch 082/150 | Loss 0.0097 | Win/lose count 17.2/21.8 (-4.600000000000023) | explore_proba 0.10\n",
            "Epoch 083/150 | Loss 0.0113 | Win/lose count 14.0/18.6 (-4.599999999999994) | explore_proba 0.10\n",
            "Epoch 084/150 | Loss 0.0113 | Win/lose count 15.2/21.3 (-6.100000000000021) | explore_proba 0.10\n",
            "Epoch 085/150 | Loss 0.0099 | Win/lose count 14.0/18.6 (-4.599999999999991) | explore_proba 0.10\n",
            "Epoch 086/150 | Loss 0.0061 | Win/lose count 18.0/20.6 (-2.6000000000000156) | explore_proba 0.10\n",
            "Epoch 087/150 | Loss 0.0069 | Win/lose count 10.8/20.4 (-9.600000000000023) | explore_proba 0.10\n",
            "Epoch 088/150 | Loss 0.0068 | Win/lose count 18.8/16.4 (2.4000000000000306) | explore_proba 0.10\n",
            "Epoch 089/150 | Loss 0.0098 | Win/lose count 11.2/20.3 (-9.100000000000007) | explore_proba 0.10\n",
            "Epoch 090/150 | Loss 0.0090 | Win/lose count 15.2/16.3 (-1.0999999999999535) | explore_proba 0.10\n",
            "Epoch 091/150 | Loss 0.0083 | Win/lose count 17.6/18.7 (-1.0999999999999979) | explore_proba 0.10\n",
            "Epoch 092/150 | Loss 0.0109 | Win/lose count 16.8/17.9 (-1.0999999999999872) | explore_proba 0.10\n",
            "Epoch 093/150 | Loss 0.0094 | Win/lose count 20.4/22.0 (-1.6000000000000583) | explore_proba 0.10\n",
            "Epoch 094/150 | Loss 0.0085 | Win/lose count 14.8/18.4 (-3.5999999999999908) | explore_proba 0.10\n",
            "Epoch 095/150 | Loss 0.0081 | Win/lose count 12.8/18.9 (-6.1) | explore_proba 0.10\n",
            "Epoch 096/150 | Loss 0.0057 | Win/lose count 19.2/19.3 (-0.10000000000001918) | explore_proba 0.10\n",
            "Epoch 097/150 | Loss 0.0062 | Win/lose count 11.6/21.2 (-9.600000000000037) | explore_proba 0.10\n",
            "Epoch 098/150 | Loss 0.0075 | Win/lose count 7.6/22.2 (-14.600000000000051) | explore_proba 0.10\n",
            "Epoch 099/150 | Loss 0.0068 | Win/lose count 14.8/18.4 (-3.599999999999987) | explore_proba 0.10\n",
            "Epoch 100/150 | Loss 0.0092 | Win/lose count 13.6/17.7 (-4.099999999999978) | explore_proba 0.10\n",
            "Epoch 101/150 | Loss 0.0030 | Win/lose count 12.8/19.9 (-7.100000000000017) | explore_proba 0.10\n",
            "Epoch 102/150 | Loss 0.0135 | Win/lose count 20.0/17.1 (2.900000000000013) | explore_proba 0.10\n",
            "Epoch 103/150 | Loss 0.0057 | Win/lose count 18.0/18.6 (-0.6000000000000014) | explore_proba 0.10\n",
            "Epoch 104/150 | Loss 0.0155 | Win/lose count 16.4/20.0 (-3.6000000000000014) | explore_proba 0.10\n",
            "Epoch 105/150 | Loss 0.0115 | Win/lose count 14.0/19.6 (-5.6000000000000085) | explore_proba 0.10\n",
            "Epoch 106/150 | Loss 0.0054 | Win/lose count 10.4/22.5 (-12.100000000000039) | explore_proba 0.10\n",
            "Epoch 107/150 | Loss 0.0191 | Win/lose count 15.6/21.2 (-5.600000000000016) | explore_proba 0.10\n",
            "Epoch 108/150 | Loss 0.0117 | Win/lose count 19.6/22.2 (-2.6000000000000547) | explore_proba 0.10\n",
            "Epoch 109/150 | Loss 0.0124 | Win/lose count 16.8/23.9 (-7.100000000000037) | explore_proba 0.10\n",
            "Epoch 110/150 | Loss 0.0145 | Win/lose count 15.2/23.3 (-8.100000000000042) | explore_proba 0.10\n",
            "Epoch 111/150 | Loss 0.0106 | Win/lose count 16.8/17.9 (-1.0999999999999872) | explore_proba 0.10\n",
            "Epoch 112/150 | Loss 0.0199 | Win/lose count 16.0/21.1 (-5.100000000000005) | explore_proba 0.10\n",
            "Epoch 113/150 | Loss 0.0125 | Win/lose count 16.0/20.1 (-4.099999999999987) | explore_proba 0.10\n",
            "Epoch 114/150 | Loss 0.0169 | Win/lose count 13.6/21.7 (-8.100000000000025) | explore_proba 0.10\n",
            "Epoch 115/150 | Loss 0.0162 | Win/lose count 13.2/23.8 (-10.600000000000055) | explore_proba 0.10\n",
            "Epoch 116/150 | Loss 0.0158 | Win/lose count 18.4/20.5 (-2.1000000000000334) | explore_proba 0.10\n",
            "Epoch 117/150 | Loss 0.0084 | Win/lose count 17.6/18.7 (-1.1000000000000014) | explore_proba 0.10\n",
            "Epoch 118/150 | Loss 0.0176 | Win/lose count 14.0/22.6 (-8.600000000000044) | explore_proba 0.10\n",
            "Epoch 119/150 | Loss 0.0105 | Win/lose count 17.2/22.8 (-5.600000000000023) | explore_proba 0.10\n",
            "Epoch 120/150 | Loss 0.0132 | Win/lose count 13.2/22.8 (-9.600000000000026) | explore_proba 0.10\n",
            "Epoch 121/150 | Loss 0.0191 | Win/lose count 14.0/22.6 (-8.600000000000001) | explore_proba 0.10\n",
            "Epoch 122/150 | Loss 0.0204 | Win/lose count 18.4/18.5 (-0.10000000000000497) | explore_proba 0.10\n",
            "Epoch 123/150 | Loss 0.0130 | Win/lose count 14.0/19.6 (-5.6000000000000085) | explore_proba 0.10\n",
            "Epoch 124/150 | Loss 0.0269 | Win/lose count 12.4/19.0 (-6.599999999999984) | explore_proba 0.10\n",
            "Epoch 125/150 | Loss 0.0215 | Win/lose count 14.0/21.6 (-7.600000000000048) | explore_proba 0.10\n",
            "Epoch 126/150 | Loss 0.0107 | Win/lose count 14.8/18.4 (-3.59999999999998) | explore_proba 0.10\n",
            "Epoch 127/150 | Loss 0.0123 | Win/lose count 14.0/26.6 (-12.600000000000044) | explore_proba 0.10\n",
            "Epoch 128/150 | Loss 0.0095 | Win/lose count 14.8/19.4 (-4.600000000000005) | explore_proba 0.10\n",
            "Epoch 129/150 | Loss 0.0102 | Win/lose count 14.0/19.6 (-5.599999999999991) | explore_proba 0.10\n",
            "Epoch 130/150 | Loss 0.0181 | Win/lose count 12.8/18.9 (-6.099999999999996) | explore_proba 0.10\n",
            "Epoch 131/150 | Loss 0.0115 | Win/lose count 16.8/21.9 (-5.100000000000023) | explore_proba 0.10\n",
            "Epoch 132/150 | Loss 0.0138 | Win/lose count 12.4/20.0 (-7.600000000000001) | explore_proba 0.10\n",
            "Epoch 133/150 | Loss 0.0101 | Win/lose count 14.4/20.5 (-6.0999999999999925) | explore_proba 0.10\n",
            "Epoch 134/150 | Loss 0.0104 | Win/lose count 10.4/20.5 (-10.10000000000001) | explore_proba 0.10\n",
            "Epoch 135/150 | Loss 0.0092 | Win/lose count 16.0/20.1 (-4.099999999999998) | explore_proba 0.10\n",
            "Epoch 136/150 | Loss 0.0067 | Win/lose count 21.6/21.7 (-0.10000000000005116) | explore_proba 0.10\n",
            "Epoch 137/150 | Loss 0.0044 | Win/lose count 14.8/19.4 (-4.599999999999991) | explore_proba 0.10\n",
            "Epoch 138/150 | Loss 0.0089 | Win/lose count 16.8/20.9 (-4.100000000000037) | explore_proba 0.10\n",
            "Epoch 139/150 | Loss 0.0133 | Win/lose count 18.4/20.5 (-2.100000000000019) | explore_proba 0.10\n",
            "Epoch 140/150 | Loss 0.0114 | Win/lose count 16.8/17.9 (-1.0999999999999837) | explore_proba 0.10\n",
            "Epoch 141/150 | Loss 0.0108 | Win/lose count 22.4/17.5 (4.899999999999999) | explore_proba 0.10\n",
            "Epoch 142/150 | Loss 0.0329 | Win/lose count 15.6/24.2 (-8.600000000000033) | explore_proba 0.10\n",
            "Epoch 143/150 | Loss 0.0067 | Win/lose count 22.0/18.6 (3.3999999999999773) | explore_proba 0.10\n",
            "Epoch 144/150 | Loss 0.0085 | Win/lose count 14.8/19.4 (-4.599999999999991) | explore_proba 0.10\n",
            "Epoch 145/150 | Loss 0.0070 | Win/lose count 14.0/23.6 (-9.600000000000005) | explore_proba 0.10\n",
            "Epoch 146/150 | Loss 0.0222 | Win/lose count 12.4/23.0 (-10.600000000000033) | explore_proba 0.10\n",
            "Epoch 147/150 | Loss 0.0104 | Win/lose count 18.4/22.5 (-4.100000000000051) | explore_proba 0.10\n",
            "Epoch 148/150 | Loss 0.0132 | Win/lose count 18.4/21.5 (-3.1000000000000547) | explore_proba 0.10\n",
            "Epoch 149/150 | Loss 0.0098 | Win/lose count 16.4/22.0 (-5.600000000000019) | explore_proba 0.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao2qup98vqIO",
        "colab_type": "code",
        "outputId": "37aa8488-9b33-4f41-dfde-ead6c8c047e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore15.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 12.5/1.0. Average score (11.5)\n",
            "Win/lose count 20.0/1.0. Average score (15.25)\n",
            "Win/lose count 16.0/0. Average score (15.5)\n",
            "Win/lose count 16.5/1.0. Average score (15.5)\n",
            "Win/lose count 6.0/0. Average score (13.6)\n",
            "Win/lose count 10.0/0. Average score (13.0)\n",
            "Win/lose count 15.5/1.0. Average score (13.214285714285714)\n",
            "Win/lose count 20.5/1.0. Average score (14.0)\n",
            "Win/lose count 11.0/1.0. Average score (13.555555555555555)\n",
            "Win/lose count 15.5/0. Average score (13.75)\n",
            "Win/lose count 16.5/1.0. Average score (13.909090909090908)\n",
            "Win/lose count 12.0/0. Average score (13.75)\n",
            "Win/lose count 0/0. Average score (12.692307692307692)\n",
            "Win/lose count 6.0/0. Average score (12.214285714285714)\n",
            "Win/lose count 1.0/0. Average score (11.466666666666667)\n",
            "Win/lose count 16.0/0. Average score (11.75)\n",
            "Win/lose count 6.5/0. Average score (11.441176470588236)\n",
            "Win/lose count 5.0/0. Average score (11.083333333333334)\n",
            "Win/lose count 13.5/0. Average score (11.210526315789474)\n",
            "Win/lose count 3.0/0. Average score (10.8)\n",
            "Final score: 10.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oVcwSx4vqIS",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s6vLOFjvqIV",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}